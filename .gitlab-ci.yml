stages:
  - validate
  - infrastructure
  - deploy
  - test

variables:
  CLUSTER_NAME: "axual-demo-cluster"
  AWS_REGION: "eu-west-1"

image: alpine:latest

before_script: |
  apk add --no-cache python3 py3-pip curl wget unzip bash ca-certificates
  pip3 install awscli --break-system-packages
  curl -LO "https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl"
  chmod +x kubectl && mv kubectl /usr/local/bin/
  curl -LO "https://get.helm.sh/helm-v3.17.0-linux-amd64.tar.gz"
  tar -zxvf helm-v3.17.0-linux-amd64.tar.gz && mv linux-amd64/helm /usr/local/bin/
  wget -O terraform.zip "https://releases.hashicorp.com/terraform/1.9.0/terraform_1.9.0_linux_amd64.zip"
  unzip -o terraform.zip -d /usr/local/bin/
  chmod +x /usr/local/bin/terraform
  aws configure set aws_access_key_id ${AWS_ACCESS_KEY_ID}
  aws configure set aws_secret_access_key ${AWS_SECRET_ACCESS_KEY}
  aws configure set region ${AWS_REGION}
  aws sts get-caller-identity

validate_terraform:
  stage: validate
  script: |
    cd terraform
    terraform init
    terraform validate
    set +e
    terraform plan -out=plan.tfplan -detailed-exitcode
    plan_exit=$?
    set -e
    if [ "$plan_exit" -eq 1 ]; then
      echo "Terraform plan failed due to configuration or credentials error."
      exit 1
    elif [ "$plan_exit" -ne 0 ] && [ "$plan_exit" -ne 2 ]; then
      echo "Terraform planning failed with unexpected exit code: $plan_exit."
      exit 1
    fi
    echo "Terraform plan succeeded (Exit code $plan_exit)."
  artifacts:
    paths:
      - terraform/plan.tfplan
    expire_in: 1 hour
  only:
    - main
    - merge_requests

deploy_infrastructure:
  stage: infrastructure
  script: |
    cd terraform
    terraform init
    terraform apply -input=false plan.tfplan
    aws eks update-kubeconfig --region ${AWS_REGION} --name ${CLUSTER_NAME} --alias ${CLUSTER_NAME}
    kubectl cluster-info
    kubectl get nodes
  dependencies:
    - validate_terraform
  only:
    - main

deploy_prerequisites:
  stage: deploy
  script: |
    helm repo add eks https://aws.github.io/eks-charts
    helm repo add mysql-operator https://mysql.github.io/mysql-operator/
    helm repo add bitnami https://charts.bitnami.com/bitnami
    helm repo update
    aws eks update-kubeconfig --region ${AWS_REGION} --name ${CLUSTER_NAME}
    EBS_ROLE_ARN=$(aws iam get-role --role-name "${CLUSTER_NAME}-ebs-csi-driver" --query 'Role.Arn' --output text)
    ALB_ROLE_ARN=$(aws iam get-role --role-name "${CLUSTER_NAME}-alb-controller-role" --query 'Role.Arn' --output text)
    helm upgrade --install aws-ebs-csi-driver eks/aws-ebs-csi-driver --namespace kube-system \
      --set controller.serviceAccount.create=true \
      --set controller.serviceAccount.annotations."eks\.amazonaws\.com/role-arn"="$EBS_ROLE_ARN" \
      --wait --timeout 5m
    helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller --namespace kube-system \
      --set clusterName=${CLUSTER_NAME} \
      --set region=${AWS_REGION} \
      --set serviceAccount.create=true \
      --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"="$ALB_ROLE_ARN" \
      --wait --timeout 5m
    timeout 300s bash -c 'until kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-ebs-csi-driver -o name 2>/dev/null | grep -q pod/; do echo "Waiting for aws-ebs-csi-driver pods..."; sleep 10; done'
    kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=aws-ebs-csi-driver -n kube-system --timeout=300s
    timeout 300s bash -c 'until kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller -o name 2>/dev/null | grep -q pod/; do echo "Waiting for aws-load-balancer-controller pods..."; sleep 10; done'
    kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=aws-load-balancer-controller -n kube-system --timeout=300s
  dependencies:
    - deploy_infrastructure
  only:
    - main

deploy_mysql:
  stage: deploy
  script: |
    aws eks update-kubeconfig --region ${AWS_REGION} --name ${CLUSTER_NAME}
    for i in 1 2 3; do helm upgrade --install mysql-operator mysql-operator/mysql-operator --namespace mysql-operator --create-namespace --wait --timeout 5m && break || sleep 30; done
    kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=mysql-operator -n mysql-operator --timeout=300s
    helm upgrade --install my-mysql-innodbcluster mysql-operator/mysql-innodbcluster --namespace mysql-operator --set credentials.root.password="${MYSQL_ROOT_PASSWORD}" --set database="wordpress" --set tls.useSelfSigned=true --set instances=1 --wait --timeout 10m
    timeout 600s bash -c 'until kubectl get pods -n mysql-operator -l app.kubernetes.io/instance=my-mysql-innodbcluster -o name 2>/dev/null | grep -q pod/; do echo "Waiting for MySQL pods..."; sleep 10; done'
    kubectl wait --for=condition=ready pod -n mysql-operator -l app.kubernetes.io/instance=my-mysql-innodbcluster --timeout=600s
    timeout 600s bash -c "until kubectl run -n mysql-operator mysql-init --image=mysql:8.0 --rm --restart=Never -- mysql -h my-mysql-innodbcluster.mysql-operator.svc.cluster.local -u root -p${MYSQL_ROOT_PASSWORD} -e \"CREATE DATABASE IF NOT EXISTS wordpress; CREATE USER IF NOT EXISTS 'wordpress'@'%' IDENTIFIED BY 'wordpress123'; GRANT ALL PRIVILEGES ON wordpress.* TO 'wordpress'@'%'; FLUSH PRIVILEGES;\"; do echo 'Retrying database bootstrap...'; sleep 10; done"
  dependencies:
    - deploy_prerequisites
  only:
    - main
  retry:
    max: 2
    when:
      - script_failure

deploy_wordpress:
  stage: deploy
  script: |
    aws eks update-kubeconfig --region ${AWS_REGION} --name ${CLUSTER_NAME}
    helm upgrade --install wordpress bitnami/wordpress --namespace default \
      --values helm/wordpress-values.yaml \
      --set ingress.hostname=wordpress.${CI_PROJECT_PATH_SLUG}.demo.axual.com \
      --wait --timeout 5m
    timeout 600s bash -c 'until kubectl get pods -l app.kubernetes.io/name=wordpress -o name 2>/dev/null | grep -q pod/; do echo "Waiting for WordPress pods..."; sleep 10; done'
    kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=wordpress --timeout=600s
    echo "Deployment Complete!"
    echo "WordPress URL http://wordpress.${CI_PROJECT_PATH_SLUG}.demo.axual.com"
    echo "Admin URL http://wordpress.${CI_PROJECT_PATH_SLUG}.demo.axual.com/wp-admin"
    echo "Username admin"
    echo "Password AdminPass123!"
  dependencies:
    - deploy_mysql
  only:
    - main

smoke_tests:
  stage: test
  script: |
    aws eks update-kubeconfig --region ${AWS_REGION} --name ${CLUSTER_NAME}
    kubectl cluster-info
    kubectl get pods -A
    kubectl get pods -l app.kubernetes.io/name=wordpress
    kubectl get pods -n mysql-operator
    kubectl get svc wordpress
    kubectl get svc -n mysql-operator my-mysql-innodbcluster
    kubectl get pvc -A
    echo "All smoke tests passed!"
  dependencies:
    - deploy_wordpress
  only:
    - main